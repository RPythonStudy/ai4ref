import psycopg2
from common.database import get_db_connection
from common.logger import log_debug, log_error

def show_table_structure():
    """
    ìƒì„±ëœ í…Œì´ë¸”ë“¤ì˜ êµ¬ì¡°ë¥¼ í‘œ í˜•íƒœë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="ai4ref",
            user="postgres",
            password="postgres"
        )
        cur = conn.cursor()
        
        # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìŠ¤í‚¤ë§ˆ í…Œì´ë¸”ë“¤)
        tables = ['papers', 'collections', 'collection_pmid', 'unique_pmid', 'filtered_pmid', 'paper_collection']
        
        for table_name in tables:
            # í…Œì´ë¸” êµ¬ì¡° ì¡°íšŒ
            cur.execute("""
                SELECT 
                    column_name,
                    data_type,
                    character_maximum_length,
                    is_nullable,
                    column_default
                FROM information_schema.columns 
                WHERE table_name = %s
                ORDER BY ordinal_position;
            """, (table_name,))
            
            columns = cur.fetchall()
            
            if not columns:
                print(f"{table_name} í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                continue
            
            # í…Œì´ë¸” í—¤ë”
            print("\n" + "="*80)
            print(f"{table_name.upper()} í…Œì´ë¸” êµ¬ì¡°".center(80))
            print("="*80)
            print(f"{'ì»¬ëŸ¼ëª…':<20} {'íƒ€ì…':<15} {'ê¸¸ì´':<8} {'NULL':<8} {'ê¸°ë³¸ê°’':<20}")
            print("-"*80)
            
            # í…Œì´ë¸” ë°ì´í„°
            for col in columns:
                column_name = col[0]
                data_type = col[1]
                max_length = str(col[2]) if col[2] else ""
                is_nullable = "YES" if col[3] == "YES" else "NO"
                default_val = str(col[4])[:18] + "..." if col[4] and len(str(col[4])) > 18 else str(col[4]) if col[4] else ""
                
                print(f"{column_name:<20} {data_type:<15} {max_length:<8} {is_nullable:<8} {default_val:<20}")
            
            # ì¸ë±ìŠ¤ ì •ë³´
            cur.execute("""
                SELECT indexname, indexdef 
                FROM pg_indexes 
                WHERE tablename = %s
                ORDER BY indexname;
            """, (table_name,))
            
            indexes = cur.fetchall()
            
            if indexes:
                print("\n" + "-"*80)
                print("ì¸ë±ìŠ¤ ì •ë³´".center(80))
                print("-"*80)
                for idx_name, idx_def in indexes:
                    print(f"- {idx_name}")
                    if "UNIQUE" in idx_def:
                        print(f"  (UNIQUE ì œì•½ì¡°ê±´)")
                    print()
            
            print("="*80 + "\n")
        
        cur.close()
        conn.close()
        
    except psycopg2.Error as e:
        log_error(f"í…Œì´ë¸” êµ¬ì¡° ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")

def get_database_summary():
    """
    ë°ì´í„°ë² ì´ìŠ¤ì˜ ê°„ë‹¨í•œ ìš”ì•½ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="ai4ref",
            user="postgres",
            password="postgres"
        )
        cur = conn.cursor()
        
        summary = {}
        tables = ['papers', 'collections', 'collection_pmid', 'unique_pmid', 'filtered_pmid', 'paper_collection']
        
        for table in tables:
            cur.execute(f"SELECT COUNT(*) FROM {table};")
            count = cur.fetchone()[0]
            summary[table] = count
        
        cur.close()
        conn.close()
        return summary
        
    except psycopg2.Error as e:
        log_error(f"ë°ì´í„°ë² ì´ìŠ¤ ìš”ì•½ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        return {}

def show_table_columns():
    """
    ê° í…Œì´ë¸”ì˜ ì»¬ëŸ¼ëª…ë§Œ ê°„ë‹¨íˆ ë³´ì—¬ì¤ë‹ˆë‹¤.
    """
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="ai4ref",
            user="postgres",
            password="postgres"
        )
        cur = conn.cursor()
        
        # í…Œì´ë¸” ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ìŠ¤í‚¤ë§ˆ í…Œì´ë¸”ë“¤)
        tables = ['papers', 'collections', 'collection_pmid', 'unique_pmid', 'filtered_pmid', 'paper_collection']
        
        print("\n" + "="*50)
        print("ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” êµ¬ì¡° (ì»¬ëŸ¼ëª…)".center(50))
        print("="*50)
        
        for table_name in tables:
            # í…Œì´ë¸” ì»¬ëŸ¼ ì¡°íšŒ
            cur.execute("""
                SELECT column_name, data_type
                FROM information_schema.columns 
                WHERE table_name = %s
                ORDER BY ordinal_position;
            """, (table_name,))
            
            columns = cur.fetchall()
            
            if not columns:
                print(f"\n{table_name.upper()}: í…Œì´ë¸”ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                continue
            
            print(f"\nğŸ“‹ {table_name.upper()} ({len(columns)}ê°œ ì»¬ëŸ¼)")
            print("-" * 30)
            
            # ì»¬ëŸ¼ëª…ê³¼ íƒ€ì…ì„ ê°„ë‹¨íˆ í‘œì‹œ
            for col_name, col_type in columns:
                # íƒ€ì… ê°„ëµí™”
                simple_type = col_type.split('(')[0]  # varchar(255) -> varchar
                if simple_type == 'character varying':
                    simple_type = 'varchar'
                elif simple_type == 'timestamp without time zone':
                    simple_type = 'timestamp'
                
                print(f"  â€¢ {col_name:<20} ({simple_type})")
        
        print("\n" + "="*50 + "\n")
        
        cur.close()
        conn.close()
        
    except psycopg2.Error as e:
        log_error(f"í…Œì´ë¸” ì»¬ëŸ¼ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")

def show_database_summary():
    """
    ë°ì´í„°ë² ì´ìŠ¤ ì£¼ìš” ì§€í‘œì™€ ì»¬ëŸ¼ë³„ ë°ì´í„° ìˆ˜ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.
    """
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="ai4ref",
            user="postgres",
            password="postgres"
        )
        cur = conn.cursor()
        
        print("\n" + "="*60)
        print("ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½".center(60))
        print("="*60)
        
        # 1. PAPERS í…Œì´ë¸” ì£¼ìš” ì§€í‘œ
        cur.execute("SELECT COUNT(*) FROM papers;")
        total_papers = cur.fetchone()[0]
        
        # ë°ì´í„° ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ì»¬ëŸ¼ í†µê³„ ì¡°íšŒ
        cur.execute("SELECT COUNT(*) FROM papers WHERE doi IS NOT NULL AND TRIM(doi) != '';")
        papers_with_doi = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM papers WHERE pmid IS NOT NULL AND TRIM(pmid) != '';")
        papers_with_pmid = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM papers WHERE title IS NOT NULL AND TRIM(title) != '';")
        papers_with_title = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM papers WHERE pdf_url IS NOT NULL AND TRIM(pdf_url) != '';")
        papers_with_pdf = cur.fetchone()[0]
        
        print(f"ğŸ“„ PAPERS: ì´ {total_papers:,}ê°œ")
        if total_papers > 0:
            print(f"   â”œâ”€ DOI ë³´ìœ : {papers_with_doi:,}ê°œ ({papers_with_doi/total_papers*100:.1f}%)")
            print(f"   â”œâ”€ PMID ë³´ìœ : {papers_with_pmid:,}ê°œ ({papers_with_pmid/total_papers*100:.1f}%)")
            print(f"   â”œâ”€ ì œëª© ë³´ìœ : {papers_with_title:,}ê°œ ({papers_with_title/total_papers*100:.1f}%)")
            print(f"   â””â”€ PDF ë§í¬: {papers_with_pdf:,}ê°œ ({papers_with_pdf/total_papers*100:.1f}%)")
        else:
            print(f"   â”œâ”€ DOI ë³´ìœ : {papers_with_doi:,}ê°œ (0.0%)")
            print(f"   â”œâ”€ PMID ë³´ìœ : {papers_with_pmid:,}ê°œ (0.0%)")
            print(f"   â”œâ”€ ì œëª© ë³´ìœ : {papers_with_title:,}ê°œ (0.0%)")
            print(f"   â””â”€ PDF ë§í¬: {papers_with_pdf:,}ê°œ (0.0%)")
        
        # 2. COLLECTIONS í…Œì´ë¸” ì£¼ìš” ì§€í‘œ
        cur.execute("SELECT COUNT(*) FROM collections;")
        total_collections = cur.fetchone()[0]
        
        # ë°ì´í„° ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  ì»¬ëŸ¼ í†µê³„ ì¡°íšŒ
        cur.execute("SELECT COUNT(*) FROM collections WHERE enabled = true;")
        enabled_collections = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM collections WHERE parent_id IS NULL;")
        root_collections = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM collections WHERE zotero_key IS NOT NULL AND TRIM(zotero_key) != '';")
        zotero_collections = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM collections WHERE search_term IS NOT NULL AND TRIM(search_term) != '';")
        searchable_collections = cur.fetchone()[0]
        
        print(f"ğŸ“ COLLECTIONS: ì´ {total_collections:,}ê°œ")
        if total_collections > 0:
            print(f"   â”œâ”€ í™œì„±í™”ë¨: {enabled_collections:,}ê°œ ({enabled_collections/total_collections*100:.1f}%)")
            print(f"   â”œâ”€ ìµœìƒìœ„: {root_collections:,}ê°œ")
            print(f"   â”œâ”€ Zotero ì—°ë™: {zotero_collections:,}ê°œ ({zotero_collections/total_collections*100:.1f}%)")
            print(f"   â””â”€ ê²€ìƒ‰ ì„¤ì •: {searchable_collections:,}ê°œ ({searchable_collections/total_collections*100:.1f}%)")
        else:
            print(f"   â”œâ”€ í™œì„±í™”ë¨: {enabled_collections:,}ê°œ (0.0%)")
            print(f"   â”œâ”€ ìµœìƒìœ„: {root_collections:,}ê°œ")
            print(f"   â”œâ”€ Zotero ì—°ë™: {zotero_collections:,}ê°œ (0.0%)")
            print(f"   â””â”€ ê²€ìƒ‰ ì„¤ì •: {searchable_collections:,}ê°œ (0.0%)")
        
        # 3. PAPER_COLLECTION ê´€ê³„ í…Œì´ë¸”
        cur.execute("SELECT COUNT(*) FROM paper_collection;")
        total_relations = cur.fetchone()[0]
        
        # ë°ì´í„° ìœ ë¬´ì™€ ê´€ê³„ì—†ì´ ëª¨ë“  í†µê³„ ì¡°íšŒ
        cur.execute("SELECT COUNT(DISTINCT paper_id) FROM paper_collection;")
        unique_papers = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(DISTINCT collection_id) FROM paper_collection;")
        unique_collections = cur.fetchone()[0]
        
        print(f"ğŸ”— PAPER_COLLECTION: ì´ {total_relations:,}ê°œ ê´€ê³„")
        if total_relations > 0:
            print(f"   â”œâ”€ ì—°ê²°ëœ ë…¼ë¬¸: {unique_papers:,}ê°œ")
            print(f"   â””â”€ ì—°ê²°ëœ ì»¬ë ‰ì…˜: {unique_collections:,}ê°œ")
        else:
            print(f"   â”œâ”€ ì—°ê²°ëœ ë…¼ë¬¸: {unique_papers:,}ê°œ")
            print(f"   â””â”€ ì—°ê²°ëœ ì»¬ë ‰ì…˜: {unique_collections:,}ê°œ")
        
        # 4. ì›Œí¬í”Œë¡œìš° í…Œì´ë¸”ë“¤ ìƒíƒœ
        cur.execute("SELECT COUNT(*) FROM collection_pmid;")
        collection_pmid_count = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM unique_pmid;")
        unique_pmid_count = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(*) FROM filtered_pmid;")
        filtered_pmid_count = cur.fetchone()[0]
        
        print(f"âš™ï¸  ì›Œí¬í”Œë¡œìš° ìƒíƒœ")
        print(f"   â”œâ”€ collection_pmid: {collection_pmid_count:,}ê°œ (Step 2: ê²€ìƒ‰ ê²°ê³¼)")
        print(f"   â”œâ”€ unique_pmid: {unique_pmid_count:,}ê°œ (Step 3a: ì¤‘ë³µ ì œê±°)")
        print(f"   â””â”€ filtered_pmid: {filtered_pmid_count:,}ê°œ (Step 3b: ìµœì¢… í•„í„°ë§)")
        
        print("="*60 + "\n")
        
        cur.close()
        conn.close()
        
    except psycopg2.Error as e:
        log_error(f"ë°ì´í„°ë² ì´ìŠ¤ ìš”ì•½ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {e}")
        print("\në°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì˜¤ë¥˜ë¡œ ìš”ì•½ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n")

def check_id_duplicates() -> None:
    """ID ì¤‘ë³µ ê²€ì‚¬ - ë°˜ë³µêµ¬ì¡°"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        log_debug("=== ID ì¤‘ë³µ ê²€ì‚¬ ===")
        
        # ê²€ì‚¬í•  í…Œì´ë¸”ê³¼ ì»¬ëŸ¼ ì„¤ì •
        checks = [
            {
                'table': 'papers',
                'column': 'pmid',
                'label': 'PMID',
                'condition': "pmid IS NOT NULL AND TRIM(pmid) != ''"
            },
            {
                'table': 'papers', 
                'column': 'doi',
                'label': 'DOI',
                'condition': "doi IS NOT NULL AND TRIM(doi) != ''"
            },
            {
                'table': 'papers', 
                'column': 'pmcid',
                'label': 'PMCID',
                'condition': "pmcid IS NOT NULL AND TRIM(pmcid) != ''"
            },
            {
                'table': 'papers', 
                'column': 'arxiv_id',
                'label': 'arXiv ID',
                'condition': "arxiv_id IS NOT NULL AND TRIM(arxiv_id) != ''"
            },
            {
                'table': 'paper_collection',
                'column': 'paper_id', 
                'label': 'Paper ID',
                'condition': "paper_id IS NOT NULL"
            },
            {
                'table': 'collections',
                'column': 'zotero_key',
                'label': 'Zotero Key',
                'condition': "zotero_key IS NOT NULL AND TRIM(zotero_key) != ''"
            },
            {
                'table': 'collection_pmid',
                'column': 'pmid',
                'label': 'Collection PMID',
                'condition': "pmid IS NOT NULL AND TRIM(pmid) != ''"
            },
            {
                'table': 'unique_pmid',
                'column': 'pmid',
                'label': 'Unique PMID',
                'condition': "pmid IS NOT NULL AND TRIM(pmid) != ''"
            },
            {
                'table': 'filtered_pmid',
                'column': 'pmid',
                'label': 'Filtered PMID',
                'condition': "pmid IS NOT NULL AND TRIM(pmid) != ''"
            }
        ]
        
        for i, check in enumerate(checks):
            try:
                if i > 0:
                    log_debug("")
                
                table_name = check['table'].upper()
                log_debug(f"[{table_name}] í…Œì´ë¸” - {check['label']} ì¤‘ë³µ ê²€ì‚¬")
                
                cur.execute(f"""
                    SELECT {check['column']}, COUNT(*) as duplicate_count
                    FROM {check['table']}
                    WHERE {check['condition']}
                    GROUP BY {check['column']}
                    HAVING COUNT(*) > 1
                    ORDER BY COUNT(*) DESC, {check['column']}
                    LIMIT 10;
                """)
                
                duplicates = cur.fetchall()
                if duplicates:
                    log_debug(f"  {check['label']} ì¤‘ë³µ ë°œê²¬: {len(duplicates)}ê°œ (ìƒìœ„ 10ê°œ í‘œì‹œ)")
                    for value, count in duplicates:
                        log_debug(f"    - {value}: {count}íšŒ ì¤‘ë³µ")
                else:
                    log_debug(f"  {check['label']} ì¤‘ë³µ ì—†ìŒ")
                    
            except Exception as e:
                log_debug(f"  {check['table']}.{check['column']} ê²€ì‚¬ ì˜¤ë¥˜: {e}")
        
        log_debug("")
        
    finally:
        cur.close()
        conn.close()

def check_column_stats() -> None:
    """ì»¬ëŸ¼ë³„ í†µê³„ ì¶œë ¥"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        log_debug("=== ì»¬ëŸ¼ í†µê³„ ===")
        
        # 1. ëª¨ë“  í…Œì´ë¸” ëª©ë¡ ì¡°íšŒ
        cur.execute("""
            SELECT tablename 
            FROM pg_tables 
            WHERE schemaname = 'public'
            ORDER BY tablename;
        """)
        tables = [row[0] for row in cur.fetchall()]
        
        for table_name in tables:
            # 2. ê° í…Œì´ë¸”ì˜ ì»¬ëŸ¼ ì •ë³´ ì¡°íšŒ
            cur.execute("""
                SELECT column_name, data_type
                FROM information_schema.columns 
                WHERE table_schema = 'public' 
                AND table_name = %s
                ORDER BY ordinal_position;
            """, (table_name,))
            columns = cur.fetchall()
            
            # 3. í…Œì´ë¸” ì´ í–‰ ìˆ˜ ì¡°íšŒ
            cur.execute(f"SELECT COUNT(*) FROM {table_name};")
            result = cur.fetchone()
            total_rows = result[0] if result else 0
            
            log_debug(f"")
            log_debug(f"[{table_name.upper()}] ì´ {total_rows:,}ê°œ í–‰")
            
            # 4. ê° ì»¬ëŸ¼ë³„ ë°ì´í„° ê°œìˆ˜ ì¡°íšŒ ë° ì¶œë ¥
            for column_name, data_type in columns:
                if data_type in ['text', 'character varying', 'varchar']:
                    # í…ìŠ¤íŠ¸ ì»¬ëŸ¼: NULLì´ ì•„ë‹ˆê³  ë¹ˆ ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš°
                    cur.execute(f"""
                        SELECT COUNT(*) 
                        FROM {table_name} 
                        WHERE {column_name} IS NOT NULL AND TRIM({column_name}) != '';
                    """)
                else:
                    # ìˆ«ì, ë‚ ì§œ ë“±: NULLì´ ì•„ë‹Œ ê²½ìš°
                    cur.execute(f"""
                        SELECT COUNT(*) 
                        FROM {table_name} 
                        WHERE {column_name} IS NOT NULL;
                    """)
                
                result = cur.fetchone()
                count = result[0] if result else 0
                percentage = (count / total_rows * 100) if total_rows > 0 else 0
                log_debug(f"  - {column_name} ({data_type}): {count:,}ê°œ ({percentage:.1f}%)")
        
        log_debug("")
        
    finally:
        cur.close()
        conn.close()

def check_workflow_status() -> None:
    """ìƒˆë¡œìš´ ë…¼ë¬¸ ìˆ˜ì§‘ ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¶„ì„"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        log_debug("=== ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¶„ì„ ===")
        
        # Step 2: collection_pmid ìƒíƒœ ë¶„ì„
        cur.execute("SELECT COUNT(*) FROM collection_pmid;")
        collection_pmid_total = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(DISTINCT collection_id) FROM collection_pmid;")
        collection_pmid_collections = cur.fetchone()[0]
        
        log_debug(f"[Step 2] collection_pmid: {collection_pmid_total:,}ê°œ PMID")
        log_debug(f"  - ê´€ë ¨ ì»¬ë ‰ì…˜: {collection_pmid_collections:,}ê°œ")
        
        # Step 3a: unique_pmid ìƒíƒœ ë¶„ì„
        cur.execute("SELECT COUNT(*) FROM unique_pmid;")
        unique_pmid_total = cur.fetchone()[0]
        
        cur.execute("SELECT COUNT(DISTINCT first_collection_id) FROM unique_pmid;")
        unique_pmid_collections = cur.fetchone()[0]
        
        log_debug(f"[Step 3a] unique_pmid: {unique_pmid_total:,}ê°œ ì¤‘ë³µì œê±° PMID")
        log_debug(f"  - ê´€ë ¨ ì»¬ë ‰ì…˜: {unique_pmid_collections:,}ê°œ")
        
        # Step 3b: filtered_pmid ìƒíƒœ ë¶„ì„
        cur.execute("SELECT COUNT(*) FROM filtered_pmid;")
        filtered_pmid_total = cur.fetchone()[0]
        
        log_debug(f"[Step 3b] filtered_pmid: {filtered_pmid_total:,}ê°œ ìµœì¢…í•„í„°ë§ PMID")
        
        # ì»¬ë ‰ì…˜ë³„ ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ
        cur.execute("""
            SELECT 
                c.name as collection_name,
                COUNT(cp.pmid) as step2_count,
                COUNT(up.pmid) as step3a_count,
                COUNT(fp.pmid) as step3b_count
            FROM collections c
            LEFT JOIN collection_pmid cp ON c.id = cp.collection_id
            LEFT JOIN unique_pmid up ON c.id = up.first_collection_id
            LEFT JOIN filtered_pmid fp ON fp.pmid = up.pmid
            GROUP BY c.id, c.name
            HAVING COUNT(cp.pmid) > 0 OR COUNT(up.pmid) > 0 OR COUNT(fp.pmid) > 0
            ORDER BY step2_count DESC
            LIMIT 10;
        """)
        
        results = cur.fetchall()
        if results:
            log_debug("")
            log_debug("[ì»¬ë ‰ì…˜ë³„] ì›Œí¬í”Œë¡œìš° ì§„í–‰ ìƒíƒœ (ìƒìœ„ 10ê°œ)")
            for name, step2, step3a, step3b in results:
                log_debug(f"  - {name}: Step2={step2}, Step3a={step3a}, Step3b={step3b}")
        
        log_debug("")
        
    except Exception as e:
        log_debug(f"ì›Œí¬í”Œë¡œìš° ìƒíƒœ ë¶„ì„ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()

def check_collection_hierarchy() -> None:
    """ì»¬ë ‰ì…˜ ê³„ì¸µ êµ¬ì¡° ë¶„ì„"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        log_debug("=== ì»¬ë ‰ì…˜ ê³„ì¸µ êµ¬ì¡° ===")
        
        # ìµœìƒìœ„ ì»¬ë ‰ì…˜ (parent_idê°€ NULL)
        cur.execute("""
            SELECT COUNT(*) 
            FROM collections 
            WHERE parent_id IS NULL;
        """)
        root_count = cur.fetchone()[0]
        log_debug(f"ìµœìƒìœ„ ì»¬ë ‰ì…˜: {root_count}ê°œ")
        
        # í•˜ìœ„ ì»¬ë ‰ì…˜ì´ ìˆëŠ” ì»¬ë ‰ì…˜
        cur.execute("""
            SELECT COUNT(DISTINCT parent_id) 
            FROM collections 
            WHERE parent_id IS NOT NULL;
        """)
        parent_count = cur.fetchone()[0]
        log_debug(f"í•˜ìœ„ ì»¬ë ‰ì…˜ì„ ê°€ì§„ ì»¬ë ‰ì…˜: {parent_count}ê°œ")
        
        # ìµœëŒ€ ê¹Šì´ ê³„ì‚°
        cur.execute("""
            WITH RECURSIVE collection_tree AS (
                SELECT id, name, parent_id, 1 as level
                FROM collections 
                WHERE parent_id IS NULL
                
                UNION ALL
                
                SELECT c.id, c.name, c.parent_id, ct.level + 1
                FROM collections c
                JOIN collection_tree ct ON c.parent_id = ct.id
            )
            SELECT MAX(level) as max_depth
            FROM collection_tree;
        """)
        
        result = cur.fetchone()
        max_depth = result[0] if result and result[0] else 0
        log_debug(f"ìµœëŒ€ ê³„ì¸µ ê¹Šì´: {max_depth}ë‹¨ê³„")
        
        # ê³„ì¸µë³„ ë¶„í¬
        cur.execute("""
            WITH RECURSIVE collection_tree AS (
                SELECT id, name, parent_id, 1 as level
                FROM collections 
                WHERE parent_id IS NULL
                
                UNION ALL
                
                SELECT c.id, c.name, c.parent_id, ct.level + 1
                FROM collections c
                JOIN collection_tree ct ON c.parent_id = ct.id
            )
            SELECT level, COUNT(*) as count
            FROM collection_tree
            GROUP BY level
            ORDER BY level;
        """)
        
        results = cur.fetchall()
        if results:
            log_debug("ê³„ì¸µë³„ ë¶„í¬:")
            for level, count in results:
                log_debug(f"  - {level}ë‹¨ê³„: {count}ê°œ")
        
        log_debug("")
        
    except Exception as e:
        log_debug(f"ì»¬ë ‰ì…˜ ê³„ì¸µ êµ¬ì¡° ë¶„ì„ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()

def check_cross_table_consistency() -> None:
    """í…Œì´ë¸” ê°„ ë°ì´í„° ì¼ê´€ì„± ê²€ì‚¬"""
    conn = get_db_connection()
    cur = conn.cursor()
    
    try:
        log_debug("=== í…Œì´ë¸” ê°„ ì¼ê´€ì„± ê²€ì‚¬ ===")
        
        # paper_collectionì˜ paper_idê°€ papersì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cur.execute("""
            SELECT COUNT(*) 
            FROM paper_collection pc
            LEFT JOIN papers p ON pc.paper_id = p.id
            WHERE p.id IS NULL;
        """)
        orphan_papers = cur.fetchone()[0]
        log_debug(f"[paper_collection] ì¡´ì¬í•˜ì§€ ì•ŠëŠ” paper_id ì°¸ì¡°: {orphan_papers}ê°œ")
        
        # paper_collectionì˜ collection_idê°€ collectionsì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cur.execute("""
            SELECT COUNT(*) 
            FROM paper_collection pc
            LEFT JOIN collections c ON pc.collection_id = c.id
            WHERE c.id IS NULL;
        """)
        orphan_collections = cur.fetchone()[0]
        log_debug(f"[paper_collection] ì¡´ì¬í•˜ì§€ ì•ŠëŠ” collection_id ì°¸ì¡°: {orphan_collections}ê°œ")
        
        # collection_pmidì˜ collection_idê°€ collectionsì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cur.execute("""
            SELECT COUNT(*) 
            FROM collection_pmid cp
            LEFT JOIN collections c ON cp.collection_id = c.id
            WHERE c.id IS NULL;
        """)
        orphan_collection_pmid = cur.fetchone()[0]
        log_debug(f"[collection_pmid] ì¡´ì¬í•˜ì§€ ì•ŠëŠ” collection_id ì°¸ì¡°: {orphan_collection_pmid}ê°œ")
        
        # unique_pmidì˜ first_collection_idê°€ collectionsì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        cur.execute("""
            SELECT COUNT(*) 
            FROM unique_pmid up
            LEFT JOIN collections c ON up.first_collection_id = c.id
            WHERE c.id IS NULL;
        """)
        orphan_unique_pmid = cur.fetchone()[0]
        log_debug(f"[unique_pmid] ì¡´ì¬í•˜ì§€ ì•ŠëŠ” first_collection_id ì°¸ì¡°: {orphan_unique_pmid}ê°œ")
        
        # collectionsì˜ parent_id ìˆœí™˜ ì°¸ì¡° ê²€ì‚¬
        cur.execute("""
            WITH RECURSIVE cycle_check AS (
                SELECT id, parent_id, ARRAY[id] as path
                FROM collections
                WHERE parent_id IS NOT NULL
                
                UNION ALL
                
                SELECT c.id, c.parent_id, cc.path || c.id
                FROM collections c
                JOIN cycle_check cc ON c.parent_id = cc.id
                WHERE c.id != ALL(cc.path)
            )
            SELECT COUNT(*)
            FROM cycle_check cc
            JOIN collections c ON cc.id = c.id
            WHERE c.id = ANY(cc.path[1:array_length(cc.path, 1)-1]);
        """)
        
        cycle_count = cur.fetchone()[0]
        log_debug(f"[collections] ìˆœí™˜ ì°¸ì¡° ë°œê²¬: {cycle_count}ê°œ")
        
        # ì¤‘ë³µ ì¡°í•© ê²€ì‚¬
        cur.execute("""
            SELECT COUNT(*) 
            FROM (
                SELECT paper_id, collection_id, COUNT(*)
                FROM paper_collection
                GROUP BY paper_id, collection_id
                HAVING COUNT(*) > 1
            ) duplicates;
        """)
        
        duplicate_relations = cur.fetchone()[0]
        log_debug(f"[paper_collection] ì¤‘ë³µ ê´€ê³„: {duplicate_relations}ê°œ")
        
        # collection_pmid ì¤‘ë³µ ê²€ì‚¬
        cur.execute("""
            SELECT COUNT(*) 
            FROM (
                SELECT collection_id, pmid, COUNT(*)
                FROM collection_pmid
                GROUP BY collection_id, pmid
                HAVING COUNT(*) > 1
            ) duplicates;
        """)
        
        duplicate_collection_pmid = cur.fetchone()[0]
        log_debug(f"[collection_pmid] ì¤‘ë³µ í•­ëª©: {duplicate_collection_pmid}ê°œ")
        
        # unique_pmid ì¤‘ë³µ ê²€ì‚¬ - pmid ì»¬ëŸ¼ì´ PRIMARY KEYì´ë¯€ë¡œ first_collection_id ê¸°ì¤€ìœ¼ë¡œ ê²€ì‚¬
        cur.execute("""
            SELECT COUNT(*) 
            FROM (
                SELECT first_collection_id, pmid, COUNT(*)
                FROM unique_pmid
                GROUP BY first_collection_id, pmid
                HAVING COUNT(*) > 1
            ) duplicates;
        """)
        
        duplicate_unique_pmid = cur.fetchone()[0]
        log_debug(f"[unique_pmid] ì¤‘ë³µ í•­ëª©: {duplicate_unique_pmid}ê°œ")
        
        # filtered_pmid ì¤‘ë³µ ê²€ì‚¬
        cur.execute("""
            SELECT COUNT(*) 
            FROM (
                SELECT pmid, COUNT(*)
                FROM filtered_pmid
                GROUP BY pmid
                HAVING COUNT(*) > 1
            ) duplicates;
        """)
        
        duplicate_filtered_pmid = cur.fetchone()[0]
        log_debug(f"[filtered_pmid] ì¤‘ë³µ í•­ëª©: {duplicate_filtered_pmid}ê°œ")
        
        log_debug("")
        
    except Exception as e:
        log_debug(f"í…Œì´ë¸” ê°„ ì¼ê´€ì„± ê²€ì‚¬ ì˜¤ë¥˜: {e}")
    finally:
        cur.close()
        conn.close()

def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ë¶„ì„ì„ ì„ íƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """
    import sys
    
    if len(sys.argv) < 2:
        print("\nì‚¬ìš©ë²•:")
        print("  python analyze_database.py summary     # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ìš”ì•½")
        print("  python analyze_database.py columns     # í…Œì´ë¸” ì»¬ëŸ¼ êµ¬ì¡°")
        print("  python analyze_database.py structure   # ìƒì„¸ í…Œì´ë¸” êµ¬ì¡°")
        print("  python analyze_database.py stats       # ì»¬ëŸ¼ë³„ í†µê³„")
        print("  python analyze_database.py duplicates  # ID ì¤‘ë³µ ê²€ì‚¬")
        print("  python analyze_database.py workflow    # ì›Œí¬í”Œë¡œìš° ìƒíƒœ")
        print("  python analyze_database.py hierarchy   # ì»¬ë ‰ì…˜ ê³„ì¸µ")
        print("  python analyze_database.py consistency # í…Œì´ë¸” ê°„ ì¼ê´€ì„±")
        print("  python analyze_database.py all         # ì „ì²´ ë¶„ì„")
        return
    
    command = sys.argv[1].lower()
    
    if command == "summary":
        show_database_summary()
    elif command == "columns":
        show_table_columns()
    elif command == "structure":
        show_table_structure()
    elif command == "stats":
        check_column_stats()
    elif command == "duplicates":
        check_id_duplicates()
    elif command == "workflow":
        check_workflow_status()
    elif command == "hierarchy":
        check_collection_hierarchy()
    elif command == "consistency":
        check_cross_table_consistency()
    elif command == "all":
        print("=== ì „ì²´ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì‹œì‘ ===\n")
        show_database_summary()
        show_table_columns()
        check_column_stats()
        check_id_duplicates()
        check_workflow_status()
        check_collection_hierarchy()
        check_cross_table_consistency()
        print("=== ì „ì²´ ë¶„ì„ ì™„ë£Œ ===")
    else:
        print(f"ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´: summary, columns, structure, stats, duplicates, workflow, hierarchy, consistency, all")

if __name__ == "__main__":
    main()
